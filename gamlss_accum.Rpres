Forecasting Periodic Accumulating Processes with Semiparametric Regression Models and Bayesian Updates*
========================================================
author: Harlan D. Harris, PhD (Director of Data Science, WeWork)
date: NY Open Statistical Programming Meetup, May 2017
autosize: true

 \* AKA, "Cancelling Classes for Fun and Profit"

```{r setup, include=FALSE}
options(stringsAsFactors = FALSE)

library(tidyverse)
library(gamlss)
library(knitr)
library(lubridate)
library(forecast)
library(magrittr)
library(timeDate)
library(bizdays)

opts_chunk$set(cache=FALSE)


```

Problem 1: Forecasting Class Size
========================================================

![Cancel Decision Illustration](prob1.png)

![Kaplan Test Prep](ktp.png)

***

* Half of test prep classes cancelled before they run (5 years ago).
* _Will class SAT482 reach profitability cutoff of 10 students?_
* Early warning to minimize impact on students, faculty, facilities.
* Impossible to predict in advance (very small Ns, dynamic market).
* Need to extrapolate, smartly.

Problem 2: Forecasting Monthly Sales
=====================================

![Monthly Sales Illustration](prob2.png)

![WeWork](wework.png)

***

* Business metric is monthly sales -- need _current_ and subsequent 3 months.
* _Will we meet our target of 400 sales in Region X next month?_
* On April 15th, we know a lot more about April sales than we did 2 weeks earlier, and probably more about May sales too.
* Next to extrapolate and update our forecasts, smartly.

Sales Data (Simulated!)
================

```{r simdata}
# 2 "years" of 12-month, 28-day data
dpm = 28; n = 2*12*dpm
mo <- function(t) 1 + (t-1) %/% dpm
dom <- function(t) 1 + (t-1) %% dpm
dat <- data_frame(t=seq.int(n),
                  t_mo=mo(t),
                  t_dom=dom(t),
                  sales = 100 + t + .002 * t^2
                  )
# add goofy offset
dat %<>% mutate(sales = sales - (t > 12*dpm) * .001 * t^2)
# add dom effect
dat %<>% mutate(sales = sales * (1 + .4 * (t_dom/28)^2))
# add both additive and multiplicitive noise
dat %<>% mutate(sales = sales * rnorm(n, 1, .1) + 
                  rnorm(n, 0, 50))
# force to be nonnegative integer
dat %<>% mutate(sales = pmax(0, round(sales)))

ggplot(dat, aes(t, sales)) + geom_point() + stat_smooth()
```


```{r data, include=FALSE}
dat <- read_csv("obfuscated_sales.csv", 
                col_types = list(col_date("%m/%d/%Y"), 
                                 col_integer())) %>%
  complete(sales_date=seq.Date(as.Date("2014-02-01"), 
                               max(sales_date), 
                               by="day"),
           fill=list(n=0))
dat$set <- with(dat,
                ifelse(sales_date >= floor_date(max(sales_date), "month") %m-% months(1),
                  "Test", "Training"))

```

```{r plot_data, echo=FALSE}
ggplot(dat, aes(sales_date, n, color=set)) + geom_point() +
  scale_color_manual(values=c("red", "black"))

ggplot(dat, aes(day(sales_date), n)) + geom_point() + stat_smooth(method='loess', span=.1)
```

* Observations: weekly, trend, day-of-month, noisy

Auto-regressive Models
======================

$$ \text{put formula here} $$

```{r ar}
monthly <- dat %>% 
  mutate(sales_month=floor_date(sales_date, "month")) %>%
  group_by(sales_month) %>%
  summarise(n=sum(n), set=set[[1]])
monthly_ts <- ts(filter(monthly, set=="Training")$n, 
                 start=c(2014,2), frequency=12)
```

***

```{r ar_plot}
autoplot(forecast(auto.arima(monthly_ts), 4)) +
  scale_y_continuous("Sales", limits=c(0,NA))
# TODO: add test set values?
```

Prophet
========

$$ log(y) = s(time) + seasonality + holiday + changepoints + error$$

* Facebook's open-sourced time-series forecasting framework.
* Does not model time as a _sequence_, but as a covariate. Can incorporate complex seasonality.
* Doesn't need clockwork periods. Can accept other covariates.
* Bayesian formulation, implemented in STAN.
* GAM-like (next!)


add a graph?

Generalized Additive Models
===========================

"Mathematically speaking, GAM is an additive modeling technique where the impact of the predictive variables is captured through smooth functions which—depending on the underlying patterns in the data—can be nonlinear:"

![GAM](gam.svg)

[GAM: The Predictive Modeling Silver Bullet](http://multithreaded.stitchfix.com/blog/2015/07/30/gam/) (Kim Larsen, Stichfix, 2015)


Accumulating Processes
======================

* Care about _sum_ of high-frequency, high-variance measurements.
* Want to update as time progresses.
* Related to hierarchical forecasting.
* Prediction intervals important.

GAMLSS
======

* [Generalized Additive Models for Location, Scale, & Shape](http://gamlss.org)
* LSS = _Independently_ model all parameters of a distribution
* Arbitrary exponential-family distributions, e.g., Skew $t$, Zero-Inflated Poisson, Beta, dozens more...

*** 

* Sales is a smooth function of time & season
* Var(Sales) is a linear function of time
* Forecast shape of uncertainty in new cases

Modeling the Prior
==================

```{r prior, echo=TRUE}
monthly %<>% 
  mutate(moy = factor(ifelse(month(sales_month) == 1, "January",
                      ifelse(month(sales_month) == 12, 
                             "December",
                             "Other"))))

monthly_training <- filter(monthly, set=="Training")
prior_fit <- gamlss(log(n) ~ cs(sales_month) + moy,
                    sigma.formula = ~ sales_month,
                    nu.formula = ~ sales_month,
                    family=TF,
                    data=monthly_training,
                    control=gamlss.control(trace=FALSE))


```

Modeling the Prior
==================

```{r prior_plots, echo=FALSE, fig.height=3, fig.width=3, dpi=150}
term.plot(prior_fit, terms = 1)
term.plot(prior_fit, terms = 2)
term.plot(prior_fit, what='sigma')
term.plot(prior_fit, what='nu')

```

Prior Fit
=========

```{r prior_fit}
preds <- with(predictAll(prior_fit),
               map_df(c(.05, .5, .95),
                      ~ data_frame(quantile=sprintf("q%0d", 100*.x), 
                                   sales_month=monthly_training$sales_month,
                                   sales=exp(qTF(.x, mu=mu, 
                                                 sigma=sigma, nu=nu))))) %>%
  spread(quantile, sales)
head(preds)

```

Prior Fit
=========

```{r prior_fit_plot, echo=TRUE}
ggplot(preds, aes(sales_month, ymin=q5, ymax=q95, y=q50)) +
  geom_ribbon(alpha=.5) + geom_line() + 
  geom_point(data=monthly, mapping=aes(y=n, ymin=NULL, ymax=NULL, color=set)) +
  xlab("") + scale_y_continuous("Sales", limits=c(0,NA)) +
  scale_color_manual("", values=c("red", "black"))
```

Bizdays
=======

```{r bizdays}

cal <- create.calendar(holidays=as.Date(holidayNYSE(2010:2020)),
                       weekdays=c("saturday", "sunday"), 
                       name="US")

#' Fraction of a month *complete*, in business days, as of the beginning of the current day
frac_bizdays <- function(dd) {
  dd <- as.Date(dd)
  prev_eom <- floor_date(dd, "month") - days(1)
  next_eom <- ceiling_date(dd, "month", change_on_boundary=TRUE)-days(1)
  so_far <- bizdays(prev_eom, dd - days(1), cal=cal) 
  month_tot <- bizdays(prev_eom, next_eom, cal=cal)
  so_far / month_tot
}

stopifnot(frac_bizdays('2016-07-29') < 1)
stopifnot(frac_bizdays('2016-07-31') == 1)
stopifnot(frac_bizdays('2016-07-01') == 0)
```

Modeling the Timecourse
=======================

* _Proportion of monthly sales_ as a function of proportion of
month in days, business days
* As of the beginning of each day, so predictors can be zero but not one
* Zero-inflated Beta is in $[0, 1)$, 3 parameters.

```{r timecourse}
daily <- dat %>%
  mutate(sales_month=floor_date(sales_date, "month")) %>%
  group_by(sales_month) %>%
  mutate(monthly_sales=sum(n),
         bod_n=lag(n, default = 0),
         prop_sales = cumsum(bod_n) / monthly_sales,
         prop_month=(day(sales_date)-1) / days_in_month(sales_date),
         prop_bizdays=frac_bizdays(sales_date)) 

```

Days and Business Days
======================

```{r timecourse_plot}
ggplot(daily, aes(prop_month, prop_sales, color=sales_date)) + 
  geom_point() +
  stat_smooth(aes(color=NULL), method='loess', color='red', span=.1) +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()

ggplot(daily, aes(prop_bizdays, prop_sales, color=sales_date)) + 
  geom_point() +
  stat_smooth(aes(color=NULL), method='loess', color='red', span=.1) +
  scale_x_continuous("Proportion of Business Days", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()

```


Modeling the Timecourse (cont)
==============================

```{r timecourse_mod}
daily_training <- filter(daily, set=="Training")
timecourse_fit <- gamlss(prop_sales ~ cs(prop_month),
                         sigma.formula = ~ cs(prop_month),
                         nu.formula = ~ cs(prop_month),
                         data=daily_training,
                         family=BEINF0)

# get this in somehow!
pdf.plot(timecourse_fit, c(1, 15, 28), min=0, max=.99, step=.01)
```

Modeling the Timecourse (cont)
==============================

```{r timecourse_mod2}
daily_preds <- with(predictAll(timecourse_fit,
                               newdata=data_frame(prop_month=(0:99)/100)),
               map_df(c(.05, .5, .95),
                      ~ data_frame(quantile=sprintf("q%0d", 100*.x), 
                                   prop_month=(0:99)/100,
                                   prop_sales=qBEINF0(.x, mu=mu, 
                                                 sigma=sigma, nu=nu)))) %>%
  spread(quantile, prop_sales)
head(daily_preds)
```

```{r timecourse_mod_plot}
ggplot(daily_preds, aes(prop_month, ymin=q5, ymax=q95, y=q50)) + 
  geom_ribbon(alpha=.5) + 
  geom_line() +
  geom_point(data=daily_training, 
             mapping=aes(ymin=NULL, ymax=NULL, y=prop_sales),
             color='blue', size=.5) +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()
```

Likelihood and Posterior, ECDFs
========================

* Prior = estimated monthly sales
* Likelihood = P(observing sales to date | prior, proportion of month)
* Posterior $\prop$ Prior * Likelihood

1. Simulate _distribution_ of proportion of sales under the timecourse model.
2. For any plausible number of final sales...
3. Multiply to get simulated distribution of sales (Likelihood).
4. Convert to ECDF.
5. Generate ECDF of Prior.
6. Multiply and normalize to get Posterior.

TODO: Review against real code, create diagram.

Visualizing and Backtesting
==========================

Impact
======


Caveats and Alternatives
=======================

daily model

Thanks
======

