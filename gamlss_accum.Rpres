Forecasting Periodic Accumulating Processes with Semiparametric Regression Models and Bayesian Updates*
========================================================
author: Harlan D. Harris, PhD (Director of Data Science, WeWork)
date: NY Open Statistical Programming Meetup, May 2017
autosize: true

 \* AKA, "Cancelling Classes for Fun and Profit"

```{r setup, include=FALSE}
options(stringsAsFactors = FALSE)

library(tidyverse)
library(gamlss)
library(knitr)
library(forecast)
library(magrittr)

opts_chunk$set(cache=FALSE)


```

Problem 1: Forecasting Class Size
========================================================

![Cancel Decision Illustration](prob1.png)

![Kaplan Test Prep](ktp.png)

***

* Half of test prep classes cancelled before they run (5 years ago).
* _Will class SAT482 reach profitability cutoff of 10 students?_
* Early warning to minimize impact on students, faculty, facilities.
* Impossible to predict in advance (very small Ns, dynamic market).
* Need to extrapolate, smartly.

Problem 2: Forecasting Monthly Sales
=====================================

![Monthly Sales Illustration](prob2.png)

![WeWork](wework.png)

***

* Business metric is monthly sales -- need _current_ and subsequent 3 months.
* _Will we meet our target of 400 sales in Region X next month?_
* On April 15th, we know a lot more about April sales than we did 2 weeks earlier, and probably more about May sales too.
* Next to extrapolate and update our forecasts, smartly.

Sales Data (Simulated!)
================

```{r simdata}
# 3 "years" of 12-month, 28-day data
dpm = 28 
mo <- function(t) 1 + (t-1) %/% dpm
dom <- function(t) 1 + (t-1) %% dpm
dat <- data_frame(t=seq.int(3*12*dpm),
                  t_mo=mo(t),
                  t_dom=dom(t),
                  bts=t_mo%%12 == 8,
                  set=factor(ifelse(t > 33*dpm, "Test", "Train"),
                             levels=c("Train", "Test")),
                  sales = (1000 + t + .001 * t^2)/10
                  )
# add bts effect
dat %<>% mutate(sales = sales * (1 + .25 * bts))
# add dom effect
dat %<>% mutate(sales = sales * (1 + .4 * (t_dom/28)^2))
# add both additive and multiplicitive noise
dat %<>% mutate(sales = sales * rnorm(3*12*dpm, 1, .3) + 
                  rnorm(3*12*dpm, 0, 30))
# force to be nonnegative integer
dat %<>% mutate(sales = pmax(0, round(sales)))

```

*** 

```{r simdata_plot, echo=FALSE}
ggplot(dat, aes(t, sales)) + 
  stat_smooth(se=FALSE, size=3) +
  geom_point(aes(color=set), alpha=.4) +
  scale_color_manual("", values=c("black", "red"))
```

Auto-regressive Models
======================

AR(p): $ X_t = c + \sum_{i=1}^p \phi_i X_{t-1} + \epsilon_t $

```{r ar}
monthly <- dat %>% 
  group_by(t_mo) %>%
  summarise(sales=sum(sales), set=set[[1]])
monthly_ts <- ts(filter(monthly, set=="Train")$sales, 
                 start=c(2014,1), frequency=12)
```

***

```{r ar_plot}
autoplot(forecast(auto.arima(monthly_ts, max.q=0), 3)) +
  geom_point(aes(time, sales), 
             data=data_frame(time=2016+(9:11)/12, 
                             sales=filter(monthly, set=="Test")$sales),
             color='red') +
  scale_y_continuous("Sales", limits=c(0,NA)) 

# autoplot(forecast(auto.arima(ts(dat$sales, start=c(2015,1), frequency=12*dpm)),100))
```

Prophet
========

$$ log(y) = s(time) + seasonality + holiday + changepoints + error$$

* Facebook's open-sourced time-series forecasting framework.
* Does not model time as a _sequence_, but as a covariate. Can incorporate complex seasonality.
* Doesn't need clockwork periods. Can accept other covariates.
* Bayesian formulation, implemented in STAN.
* GAM-like (next!)


add a graph?

Generalized Additive Models
===========================

"Mathematically speaking, GAM is an additive modeling technique where the impact of the predictive variables is captured through smooth functions which—depending on the underlying patterns in the data—can be nonlinear:"

![GAM](gam.svg)

[GAM: The Predictive Modeling Silver Bullet](http://multithreaded.stitchfix.com/blog/2015/07/30/gam/) (Kim Larsen, Stichfix, 2015)


Accumulating Processes
======================

* Care about _sum_ of high-frequency, high-variance measurements.
* Want to update as time progresses.
* Related to hierarchical forecasting.
* Prediction intervals important.

GAMLSS
======

* [Generalized Additive Models for Location, Scale, & Shape](http://gamlss.org)
* LSS = _Independently_ model all parameters of a distribution
* Arbitrary exponential-family distributions, e.g., Skew $t$, Zero-Inflated Poisson, Beta, dozens more...

*** 

* Sales is a smooth function of time & season
* Var(Sales) is a linear function of time
* Forecast shape of uncertainty in new cases

Modeling the Prior
==================

```{r prior, echo=TRUE}
monthly %<>% 
  mutate(bts = factor(ifelse((t_mo-1)%%12 == 7, "BTS", "Normal")))
                      

monthly_training <- filter(monthly, set=="Train")
prior_fit <- gamlss(log(sales) ~ cs(t_mo) + bts,
                    sigma.formula = ~ t_mo,
                    nu.formula = ~ t_mo,
                    family=TF,
                    data=monthly_training,
                    control=gamlss.control(trace=FALSE))


```

Modeling the Prior
==================

```{r prior_plots, echo=FALSE, fig.height=3, fig.width=3, dpi=150}
term.plot(prior_fit, terms = 1)
term.plot(prior_fit, terms = 2)
term.plot(prior_fit, what='sigma')
term.plot(prior_fit, what='nu')

```

Prior Fit
=========

```{r prior_fit}
preds <- with(predictAll(prior_fit),
               map_df(c(.05, .5, .95),
                      ~ data_frame(quantile=sprintf("q%0d", 100*.x), 
                                   t_mo=monthly_training$t_mo,
                                   sales=exp(qTF(.x, mu=mu, 
                                                 sigma=sigma, nu=nu))))) %>%
  spread(quantile, sales)
head(preds)

```

Prior Fit
=========

```{r prior_fit_plot, echo=TRUE}
ggplot(preds, aes(t_mo, ymin=q5, ymax=q95, y=q50)) +
  geom_ribbon(alpha=.5) + geom_line() + 
  geom_point(data=monthly, mapping=aes(y=sales, ymin=NULL, ymax=NULL, color=set)) +
  xlab("") + scale_y_continuous("Sales", limits=c(0,NA)) +
  scale_color_manual("", values=c("red", "black"))
```

Likelihood and Posterior, ECDFs
========================

* Prior = estimated monthly sales
* Likelihood = P(observing sales to date | prior, proportion of month)
* Posterior $\prop$ Prior * Likelihood

$$
P(\text{forecast sales}=y|\text{sales to date}=x) \propto P(\text{sales to date}=x | \text{fraction of month, forecast sales}=y) 
\cdot P(\text{forecast sales}=y) \\
\propto P(\text{fraction sales to date}=\frac{x}{y}|\text{fraction of month}) \cdot P(\text{forecast sales} = y)
$$

*** 

1. Simulate _distribution_ of proportion of sales under the timecourse model.
2. For any plausible number of final sales...
3. Multiply to get simulated distribution of sales (Likelihood).
4. Convert to ECDF.
5. Generate ECDF of Prior.
6. Multiply and normalize to get Posterior.


Modeling the Timecourse
=======================

* _Proportion of monthly sales_ as a function of proportion of
month in days
* As of the beginning of each day, so predictors can be zero but not one
* Zero-inflated Beta is in $[0, 1)$, 3 parameters.

```{r timecourse}
daily <- dat %>%
  group_by(t_mo) %>%
  mutate(monthly_sales=sum(sales),
         bod_sales=lag(sales, default = 0),
         prop_sales = cumsum(bod_sales) / monthly_sales,
         prop_month=(t_dom-1) / dpm) %>% ungroup()
head(daily)

```

Days and Business Days
======================

```{r timecourse_plot}
ggplot(daily, aes(prop_month, prop_sales, color=t_mo)) + 
  geom_point() +
  stat_smooth(aes(color=NULL), color='red') +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()

```


Modeling the Timecourse (cont)
==============================

```{r timecourse_mod}
daily_training <- filter(daily, set=="Train")
timecourse_fit <- gamlss(prop_sales ~ cs(prop_month),
                         sigma.formula = ~ cs(prop_month),
                         nu.formula = ~ cs(prop_month),
                         data=daily_training,
                         family=BEINF0)

# get this in somehow!
pdf.plot(timecourse_fit, c(1, 15, 28), min=0, max=.99, step=.01)
```

Modeling the Timecourse (cont)
==============================

Model gives distribution parameters -- can get quantiles from there, e.g.:

```{r timecourse_forecast} 
# predict 5th percentile of 1/4 & 3/4 of the way through
with(predictAll(timecourse_fit, newdata=data_frame(prop_month=c(.25, .75))),
     qBEINF0(.05,  mu=mu, sigma=sigma, nu=nu))
```

```{r timecourse_mod2, echo=FALSE}
daily_preds <- with(predictAll(timecourse_fit,
                               newdata=data_frame(prop_month=(0:99)/100)),
               map_df(c(.05, .5, .95),
                      ~ data_frame(quantile=sprintf("q%0d", 100*.x), 
                                   prop_month=(0:99)/100,
                                   prop_sales=qBEINF0(.x, mu=mu, 
                                                 sigma=sigma, nu=nu)))) %>%
  spread(quantile, prop_sales)
head(daily_preds)
```

***

```{r timecourse_mod_plot}
ggplot(daily_preds, aes(prop_month, ymin=q5, ymax=q95, y=q50)) + 
  geom_ribbon(alpha=.5) + 
  geom_line() +
  geom_point(data=daily_training, 
             mapping=aes(ymin=NULL, ymax=NULL, y=prop_sales),
             color='blue', size=.5) +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()
```

Updating
========

February 10, 2017. 408 sales. Panic??

```{r std}
fc_day <- filter(daily, sales_month == as.Date("2017-02-01")) %>%
  mutate(bod_n_cumul = cumsum(bod_n)) %>%
  filter(sales_date == as.Date("2017-02-10"))

dSales <- function(sales) {
  suppressWarnings(
    with(predictAll(sales1, tt$test[1,], data=tt$train), dTF(log(sales), mu=mu, sigma=sigma, nu=nu))
  )
}

prior <- 
```

Visualizing and Backtesting
==========================

Impact
======


Caveats and Alternatives
=======================

daily model

Thanks
======

