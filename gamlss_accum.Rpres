<style>
.reveal pre code {
  font-size: 1em;
}
.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 90%;
    text-align:center; width:100%;
}
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}
.reveal h1, .reveal h2, .reveal h3 {
  word-wrap: normal;
  hyphens: none;
}
</style>

Forecasting Periodic Accumulating Processes with Semiparametric Regression Models and Bayesian Updates*
========================================================
author: Harlan D. Harris, PhD
date: NY Open Statistical Programming Meetup, May 2017
autosize: true

 \* AKA, "Cancelling Classes for Fun and Profit"
 
<div class="footer">Twitter: @nyhackr, @harlanh</div>

```{r setup, include=FALSE}
options(stringsAsFactors = FALSE)

library(tidyverse)
library(gamlss)
library(knitr)
library(forecast)
library(magrittr)

opts_chunk$set(cache=TRUE, dpi=150)

theme_set(theme_minimal())
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
</div>
</center>

Problem 1: Forecasting Class Size
========================================================

```{r forecasting_class_plot, echo=FALSE, fig.height=3, fig.width=5, dpi=150}
data_frame(days=c(-8.13653924223036, -41.2764017452733, -4.97421451108523, -8.69979094900191, 
-3.51587212830782, -12.1954079083147, -3.37867442829227, -19.4938695016215, 
-12.9251936185629, -8.32626658678055, -32.7134362144356, -9.06191221624613
)) %>%
  ggplot(aes(days)) + 
  geom_density(fill='grey', adjust=2) +
  geom_rug() +
  scale_x_continuous("Days Before Start",
                     limits=c(NA,0)) +
  ylab("") +
  annotate("segment", x = -14, xend = -14, 
           y = .045, yend = .035,
           colour="blue", size=1.5,
           arrow=arrow()) 

```

***

* _Cancel or Run?_
* Early Warning System
* Imprecision, Accumulating Data

Problem 2: Forecasting Monthly Sales
=====================================

```{r sales_plot, echo=FALSE, fig.height=3, fig.width=5, dpi=150}
data_frame(x=1:100, mon=sort(rep(1:4,25)),
           y=100+.5*x+.005*(x**1.1)) %>%
  group_by(mon) %>%
  mutate(y2=cumsum(y * rnorm(25, mean = 1, sd=.5))) %>%
  ggplot(aes(x, y2, group=mon)) + 
  geom_line() +
  scale_x_continuous("Month",
                     breaks=c(0,25,50,75,100),
       labels=1:5) +
  ylab("Monthly Sales to Date") +
  annotate("segment", x = 12, xend = 12, 
           y = 2700, yend = 1700,
           colour="blue", size=1.5,
           arrow=arrow()) 

```

***

* _Will We Meet Sales Targets?_
* Early Warning System
* Imprecision, Accumulating Data

Desiderata
======================

* Care about _sum_ of high-variance measurements.
* Grouping is part of data-generating process; not arbitrary.
* Want updates as time progresses.
* Want prediction intervals (honest uncertainty).

Sales Data (Simulated!)
================

```{r simdata}
# 3 "years" of 12-month, 28-day data
dpm = 28 
mo <- function(t) 1 + (t-1) %/% dpm
dom <- function(t) 1 + (t-1) %% dpm
dat <- tibble(t=seq.int(3*12*dpm),
              t_mo=mo(t),
              t_dom=dom(t),
              bts=t_mo%%12 == 8, # Back to School!
              set=factor(ifelse(t > 33*dpm,
                           "Test", "Train"),
                 levels=c("Train", "Test")),
              sales = (1000 + t + .001 * t^2)/10)
# add bts effect
dat %<>% mutate(sales = sales * (1 + .25 * bts))
# add dom effect
dat %<>% mutate(sales = sales * (1 + .4 *
                        (t_dom/28)^2))
# add both additive and multiplicitive noise
dat %<>% mutate(sales = sales *
                rnorm(3*12*dpm, 1, .3) + 
                rnorm(3*12*dpm, 0, 30))
# force to be *nonnegative integer*
dat %<>% mutate(sales = pmax(0, round(sales)))
```

*** 

```{r simdata_plot, echo=FALSE}
ggplot(dat, aes(t, sales)) + 
  stat_smooth(se=FALSE, size=3) +
  geom_point(aes(color=set), alpha=.4) +
  scale_color_manual("", values=c("black", "red"))
```

Divide and Conquer
==================

```{r monthly}
monthly <- dat %>% 
  group_by(t_mo, set, bts) %>%
  summarise(sales=sum(sales))
glimpse(monthly)
```

***

```{r daily}
daily <- dat %>%
  group_by(t_mo) %>%
  mutate(monthly_sales=sum(sales),
         bod_sales=lag(sales, default = 0),
         prop_sales = cumsum(bod_sales) /
                      monthly_sales,
         prop_month=(t_dom-1) / dpm) %>% ungroup()
glimpse(daily)
```

Divide and Conquer
==================

```{r prior_graph, echo=FALSE, fig.height=3, fig.width=4}
ggplot(monthly, aes(t_mo, sales, color=set)) +
  geom_line() +
  scale_color_manual("", values=c("black", "red")) +
  scale_x_continuous("Month", breaks=(1:3)*12) +
  scale_y_continuous("Sales", limits = c(0,NA)) +
  ggtitle("Monthly Model (Empirical Prior)") 
  
```

***

```{r timecourse_plot1, echo=FALSE, fig.height=3, fig.width=4}

ggplot(daily, aes(prop_month, prop_sales, group=t_mo, color=set)) +
  geom_line() +
  scale_color_manual("", values=c("black", "red")) +
  scale_x_continuous("Prop. of Month") +
  scale_y_continuous("Prop. Sales to Date", limits = c(0,NA)) +
  ggtitle("Timecourse Model (part of Likelihood)") 
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
</div>
</center>

Bayes Rule
==========

* Prior = monthly sales estimate, prior to seeing any sales
* Likelihood = P(observing sales to date | specific prior)
* Posterior = current estimate; prior updated by sales to date

$$
P(\text{forecast sales}=y \vert \text{sales to date}=x) \propto \\
  P(\text{sales to date}=x | \text{frac of month}=z, \text{forecast sales}=y) \cdot \\ P(\text{forecast sales}=y) \\
\text{or} \\
P(\text{fraction sales to date}=\frac{x}{y}|\text{fraction of month}=z)
\cdot P(\text{forecast sales} = y)
$$


Modeling the Prior, Conceptually
================================

```{r prior_concep, echo=FALSE, fig.height=3, fig.width=4}
tibble(Sales=500:1500, d=dnorm(Sales, mean=1000, sd=100)) %>%
  ggplot(aes(Sales, d)) + 
  geom_line() +
  ylab("") 
```

***

$$ \text{sales} = f(t,x) + N(0, \sigma) \\
\text{sales} = f(t,x) + N(0, g(t,x)) \\
\text{sales} = f(t,x) + ?(0, g(t,x), h(t,x)) $$


Generalized Additive Models
===========================

"Mathematically speaking, GAM is an additive modeling technique where the impact of the predictive variables is captured through smooth functions which—depending on the underlying patterns in the data—can be nonlinear:"

![GAM](gam.png)

[GAM: The Predictive Modeling Silver Bullet](http://multithreaded.stitchfix.com/blog/2015/07/30/gam/) (Kim Larsen, Stichfix, 2015)

Prophet
========

* Facebook's [open-sourced](https://facebookincubator.github.io/prophet/) time-series Bayesian forecasting framework.
* Time is a covariate; Complex seasonality; Non-clockwork periods. 

$$ log(y) = s(time) + seasonality + holiday + changepoints + error$$

<center>
<img src="prophet.png" alt="Prophet" style="height: 300px;"/>
</center>

GAMLSS
======

* [Generalized Additive Models for Location, Scale, & Shape](http://gamlss.org)
* LSS = _Independently_ model all parameters of a distribution
* Arbitrary exponential-family distributions, e.g., Skew $t$, Zero-Inflated Poisson, Beta, dozens more...
* Forecast _shape of uncertainty_ in new cases

Here:

* Sales ~ spline(time, back to school)
* Var(Sales) ~ time 
* Tail-heaviness(Sales) ~ time


Modeling the Prior
==================

```{r prior, echo=TRUE}
monthly_training <- filter(monthly, set=="Train")
prior_fit <- gamlss(log(sales) ~ cs(t_mo) + bts,
                    sigma.formula = ~ t_mo,
                    nu.formula = ~ t_mo,
                    family=TF,
                    data=monthly_training,
            control=gamlss.control(trace=FALSE))
```

***

```{r prior_fit_out, echo=FALSE}
prior_fit
```


Modeling the Prior
==================

<center>
```{r prior_plots, echo=FALSE, fig.height=1.9, fig.width=3, dpi=150}
par(mai=c(.5,.54,.2,.25))
term.plot(prior_fit, terms = 1); title("Loc, cs(t_mo)")
term.plot(prior_fit, terms = 2); title("Loc, bts")
term.plot(prior_fit, what='sigma'); title("Scale, t_mo")
term.plot(prior_fit, what='nu'); title("Shape, t_mo")

```
</center>

Prior Computation
=========

```{r prior_fit, message=FALSE, warning=FALSE, results='hide'}
prior_dist <- function(t_mo, bts, 
                       sales_range=2000:15000) {
  with(predictAll(prior_fit, 
                  newdata=data.frame(t_mo=t_mo,
                                     bts=bts)),
       tibble(sales=sales_range,
              d=dTF(log(sales_range), mu=mu, 
                    sigma=sigma, nu=nu),
              t_mo=t_mo, bts=bts) %>%
         mutate(d=d/sum(d)))
}
samp_priors <- tibble(t_mo=c(15,36), 
                      bts=c(FALSE, TRUE)) %>%
  by_row(~ prior_dist(.$t_mo, .$bts), 
         .collate='rows') 
```

*** 

```{r oneprior, echo=FALSE, fig.height=3, fig.width=4}
samp_priors %>%
  ggplot(aes(sales, d, group=t_mo, color=t_mo)) + 
  geom_line(size=1.2) +
  xlab("Sales") + ylab("") + 
  theme(legend.position = 'none') 
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
<h1>3. Updating the Prior</h1> 
</div>
</center>

Modeling the Likelihood, Conceptually
========================
left: 40%

```{r likelihood_concept, echo=FALSE, fig.height=3, fig.width=4}
tibble(month_prop=c(.03, .5, .90)) %>%
  by_row(~ tibble(sales_prop=(0:99)/100,
                  d=dBEINF0(sales_prop, mu=.$month_prop,
                            sigma=.1, nu=.2)),
         .collate = 'rows') %>%
  ggplot(aes(sales_prop, d, color=factor(month_prop))) +
  geom_line(size=1.5) +
  facet_grid(factor(month_prop) ~ .) +
  xlab("Sales Proportion") +
  theme(legend.position = 'none') +
  ggtitle("Example Month Proportions")
```

***

$$
P(\text{sales}=y \vert \text{sales to date}=x) \propto \\
  P(\text{sales to date}=x | \text{frac of month}=z, \text{sales}=y) \cdot \\ P(\text{sales}=y) \\
\text{or} \\
P(\text{fraction sales to date}=\frac{x}{y}|\text{fraction of month}=z)
\cdot \\
P(\text{sales} = y)
$$

Modeling the Likelihood
==============================
left:45%

```{r timecourse_mod}
daily_training <- filter(daily, 
                         set=="Train")
timecourse_fit <- 
  gamlss(prop_sales ~ cs(prop_month),
         sigma.formula = ~ cs(prop_month),
         nu.formula = ~ cs(prop_month),
         data=daily_training,
         family=BEINF0)
```

***

```{r timecourse_mod_out, echo=FALSE}
timecourse_fit
```

Modeling the Likelihood
==============================

<center>
```{r likelihood_plots, echo=FALSE, fig.height=1.9, fig.width=3, dpi=150}
par(mai=c(.5,.54,.2,.25))
term.plot(timecourse_fit, what='mu'); title("Loc, cs(prop_month)")
term.plot(timecourse_fit, what='sigma'); title("Scale, cs(prop_month)")
term.plot(timecourse_fit, what='nu'); title("Shape, cs(prop_month)")

```
</center>

Likelihood Computation
======================
left:55%

```{r likelihood_fit, message=FALSE, warning=FALSE, results='hide'}
likelihood_dist <- function(prop_month, sales_to_date,
                            sales_range=2000:15000) {
  with(predictAll(timecourse_fit, 
          newdata=data.frame(prop_month=prop_month)),
     tibble(prop_sales=pmin(.999, 
                        sales_to_date / sales_range),
            sales=sales_range,
            d=dBEINF0(prop_sales, mu=mu, 
                      sigma=sigma, nu=nu)) %>%
       mutate(d=d/sum(d)))
}

samp_likelihoods <- tibble(prop_month=c(.03, .5, .90),
                           std=c(200, 3000, 5000)) %>%
  by_row(~ likelihood_dist(.$prop_month, .$std), 
         .collate='rows') 
```

*** 

```{r onelh, echo=FALSE, fig.height=3, fig.width=4}
samp_likelihoods %>%
  mutate(label=sprintf("%0.2f / %d", prop_month, std)) %>%
  ggplot(aes(sales, d, color=label)) + 
  geom_line(size=1.2) +
  xlab("Sales") + ylab("") + 
  facet_grid(label ~ ., scales = "free_y") +
  theme(legend.position = 'none') +
  ggtitle("Modeled Likelihoods")
```

Computing the Posterior
========================

$$
\forall y, P(\text{sales}=y \vert \text{sales to date}=x) \propto \\
  P(\text{sales to date}=x | \text{frac of month}=z, \text{sales}=y) \cdot \\ P(\text{sales}=y) 
$$

Algorithm:

* For all plausible final sales numbers,
* Compute the non-normalized _prior_ and _likelihood_ values & multiply,
* Then normalize so the _posterior_ is a distribution.
* Read off quantiles as needed.

Scenario
===============

<h2>
It's December 10th, 2016. We've seen 4000 sales to date. Will we hit
our goal of 10,000 sales?
</h2>

```{r sample_prior, results='hide'}
sample_prior <- prior_dist(36, FALSE)

sales_mode <- 
  function(dd) dd$sales[[which.max(dd$d)]]
sales_thresh <- 
  function(dd, th=10000) sum(dd$d[dd$sales >= th])
```

<center><h2>Maybe?</h2></center>

***

```{r sample_prior_plot, echo=FALSE, fig.height=3, fig.width=4}
sample_prior %>%
  ggplot(aes(sales, d)) +
  geom_line(size=1.5) + 
  geom_vline(xintercept=10000, color='blue') +
  scale_y_continuous("", labels=NULL) +
  xlab("Sales") +
  ggtitle("Prior", paste("Mode = ", sales_mode(sample_prior), 
                "; P(Sales > 10k) =",
                round(sales_thresh(sample_prior), digits=3)))

```

Likelihood
==========

```{r sample_llh, results='hide'}
sample_llh <- 
  likelihood_dist(prop_month = 10/28,
                  sales_to_date = 4000)
```

<center><h2>Chickens Counted!</h2></center>

***

```{r sample_llh_plot, echo=FALSE, fig.height=3, fig.width=4}
sample_llh %>%
  ggplot(aes(sales, d)) +
  geom_line(size=1.5) + 
  geom_vline(xintercept=10000, color='blue') +
  scale_y_continuous("", labels=NULL) +
  xlab("Sales") +
  ggtitle("Likelihood", paste("Mode = ", sales_mode(sample_llh), 
                "; P(Sales > 10k) =",
                round(sales_thresh(sample_llh), digits=3)))

```

Responsible Bayesians
=====================

```{r sample_post}
sample_post <- data_frame(sales=sample_prior$sales,
                          d=sample_prior$d * sample_llh$d) %>%
  mutate(d = d/sum(d))
```

<center><h2>Back to work.</h2></center>

***

```{r sample_post_plot, echo=FALSE, fig.height=3, fig.width=4}
sample_post %>%
  ggplot(aes(sales, d)) +
  geom_line(size=1.5) + 
  geom_vline(xintercept=10000, color='blue') +
  scale_y_continuous("", labels=NULL) +
  xlab("Sales") +
  ggtitle("Posterior", paste("Mode = ", sales_mode(sample_post), 
                "; P(Sales > 10k) =",
                round(sales_thresh(sample_post), digits=3)))

```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
<h1>3. Updating the Prior</h1> 
<h1>4. Step Back</h1> 
</div>
</center>

Visualizing and Backtesting
==========================

Impact
======


Caveats and Alternatives
=======================

daily model

Takeaways
======
type:section

* Bayesian Update for Accumulation
* GAMLSS for Flexible Distribution Models
* Honest Uncertainty

Harlan D. Harris, PhD <br>
[Twitter](http://twitter.com/harlanh), 
[Medium](http://medium.com/@harlanh), 
[GitHub](http://github.com/HarlanH): @harlanh

[This Presentation on GitHub](https://github.com/HarlanH/gamlss_accum)

Auto-regressive Models
======================

$$ X_t = c + \sum_{i=1}^p \phi_i X_{t-1} + \epsilon_t $$

```{r ar}
monthly_ts <- ts(filter(monthly, 
                        set=="Train")$sales, 
                 start=c(2014,1), frequency=12)
monthly_fc <- forecast(auto.arima(monthly_ts, 
                                  max.q=0), 3)
```

***

```{r ar_plot, echo=FALSE}
p <- autoplot(monthly_fc) +
  geom_point(aes(time, sales), 
             data=tibble(time=2016+(9:11)/12, 
              sales=filter(monthly, set=="Test")$sales),
             color='red') +
  scale_y_continuous("Sales", limits=c(0,NA)) +
  theme_minimal()
p
```
