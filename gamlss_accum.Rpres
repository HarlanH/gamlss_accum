<style>
.reveal pre code {
  font-size: 1em;
}
.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 90%;
    text-align:center; width:100%;
}
.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
}
.reveal h1, .reveal h2, .reveal h3 {
  word-wrap: normal;
  hyphens: none;
}
</style>

Forecasting Periodic Accumulating Processes with Semiparametric Regression Models and Bayesian Updates*
========================================================
author: Harlan D. Harris, PhD
date: NY Open Statistical Programming Meetup, May 2017
autosize: true

 \* AKA, "Cancelling Classes for Fun and Profit"
 
<div class="footer">Twitter: @nyhackr, @harlanh</div>

```{r setup, include=FALSE}
options(stringsAsFactors = FALSE)

library(tidyverse)
library(gamlss)
library(knitr)
library(forecast)
library(magrittr)

opts_chunk$set(cache=TRUE, dpi=150)

theme_set(theme_minimal())
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
</div>
</center>

Problem 1: Forecasting Class Size
========================================================

```{r forecasting_class_plot, echo=FALSE, fig.height=3, fig.width=5, dpi=150}
data_frame(days=c(-8.13653924223036, -41.2764017452733, -4.97421451108523, -8.69979094900191, 
-3.51587212830782, -12.1954079083147, -3.37867442829227, -19.4938695016215, 
-12.9251936185629, -8.32626658678055, -32.7134362144356, -9.06191221624613
)) %>%
  ggplot(aes(days)) + 
  geom_density(fill='grey', adjust=2) +
  geom_rug() +
  scale_x_continuous("Days Before Start",
                     limits=c(NA,0)) +
  ylab("") +
  annotate("segment", x = -14, xend = -14, 
           y = .045, yend = .035,
           colour="blue", size=1.5,
           arrow=arrow()) 

```

***

* _Cancel or Run?_
* Early Warning System
* Imprecision, Accumulating Data

Problem 2: Forecasting Monthly Sales
=====================================

```{r sales_plot, echo=FALSE, fig.height=3, fig.width=5, dpi=150}
data_frame(x=1:100, mon=sort(rep(1:4,25)),
           y=100+.5*x+.005*(x**1.1)) %>%
  group_by(mon) %>%
  mutate(y2=cumsum(y * rnorm(25, mean = 1, sd=.5))) %>%
  ggplot(aes(x, y2, group=mon)) + 
  geom_line() +
  scale_x_continuous("Month",
                     breaks=c(0,25,50,75,100),
       labels=1:5) +
  ylab("Monthly Sales to Date") +
  annotate("segment", x = 12, xend = 12, 
           y = 2700, yend = 1700,
           colour="blue", size=1.5,
           arrow=arrow()) 

```

***

* _Will We Meet Sales Targets?_
* Early Warning System
* Imprecision, Accumulating Data

Desiderata
======================

* Care about _sum_ of high-variance measurements.
* Grouping is part of data-generating process; not arbitrary.
* Want updates as time progresses.
* Want prediction intervals (honest uncertainty).

Sales Data (Simulated!)
================

```{r simdata}
# 3 "years" of 12-month, 28-day data
dpm = 28 
mo <- function(t) 1 + (t-1) %/% dpm
dom <- function(t) 1 + (t-1) %% dpm
dat <- tibble(t=seq.int(3*12*dpm),
              t_mo=mo(t),
              t_dom=dom(t),
              bts=t_mo%%12 == 8, # Back to School!
              set=factor(ifelse(t > 33*dpm,
                           "Test", "Train"),
                 levels=c("Train", "Test")),
              sales = (1000 + t + .001 * t^2)/10)
# add bts effect
dat %<>% mutate(sales = sales * (1 + .25 * bts))
# add dom effect
dat %<>% mutate(sales = sales * (1 + .4 *
                        (t_dom/28)^2))
# add both additive and multiplicitive noise
dat %<>% mutate(sales = sales *
                rnorm(3*12*dpm, 1, .3) + 
                rnorm(3*12*dpm, 0, 30))
# force to be *nonnegative integer*
dat %<>% mutate(sales = pmax(0, round(sales)))
```

*** 

```{r simdata_plot, echo=FALSE}
ggplot(dat, aes(t, sales)) + 
  stat_smooth(se=FALSE, size=3) +
  geom_point(aes(color=set), alpha=.4) +
  scale_color_manual("", values=c("black", "red"))
```

Divide and Conquer
==================

```{r monthly}
monthly <- dat %>% 
  group_by(t_mo, set, bts) %>%
  summarise(sales=sum(sales))
glimpse(monthly)
```

***

```{r daily}
daily <- dat %>%
  group_by(t_mo) %>%
  mutate(monthly_sales=sum(sales),
         bod_sales=lag(sales, default = 0),
         prop_sales = cumsum(bod_sales) /
                      monthly_sales,
         prop_month=(t_dom-1) / dpm) %>% ungroup()
glimpse(daily)
```

Divide and Conquer
==================

```{r prior_graph, echo=FALSE, fig.height=3, fig.width=4}
ggplot(monthly, aes(t_mo, sales, color=set)) +
  geom_line() +
  scale_color_manual("", values=c("black", "red")) +
  scale_x_continuous("Month", breaks=(1:3)*12) +
  scale_y_continuous("Sales", limits = c(0,NA)) +
  ggtitle("Monthly Model (Empirical Prior)") 
  
```

***

```{r timecourse_plot1, echo=FALSE, fig.height=3, fig.width=4}

ggplot(daily, aes(prop_month, prop_sales, group=t_mo, color=set)) +
  geom_line() +
  scale_color_manual("", values=c("black", "red")) +
  scale_x_continuous("Prop. of Month") +
  scale_y_continuous("Prop. Sales to Date", limits = c(0,NA)) +
  ggtitle("Timecourse Model (part of Likelihood)") 
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
</div>
</center>

Bayes Rule
==========

* Prior = monthly sales estimate, prior to seeing any sales
* Likelihood = P(observing sales to date | specific prior)
* Posterior = current estimate; prior updated by sales to date

$$
P(\text{forecast sales}=y \vert \text{sales to date}=x) \propto \\
  P(\text{sales to date}=x | \text{frac of month}=z, \text{forecast sales}=y) \cdot \\ P(\text{forecast sales}=y) \\
\text{or} \\
P(\text{fraction sales to date}=\frac{x}{y}|\text{fraction of month}=z)
\cdot P(\text{forecast sales} = y)
$$


Modeling the Prior, Conceptually
================================

```{r prior_concep, echo=FALSE, fig.height=3, fig.width=4}
tibble(Sales=500:1500, d=dnorm(Sales, mean=1000, sd=100)) %>%
  ggplot(aes(Sales, d)) + 
  geom_line() +
  ylab("") 
```

***

$$ \text{sales} = f(t,x) + N(0, \sigma) \\
\text{sales} = f(t,x) + N(0, g(t,x)) \\
\text{sales} = f(t,x) + ?(0, g(t,x), h(t,x)) $$


Generalized Additive Models
===========================

"Mathematically speaking, GAM is an additive modeling technique where the impact of the predictive variables is captured through smooth functions which—depending on the underlying patterns in the data—can be nonlinear:"

![GAM](gam.png)

[GAM: The Predictive Modeling Silver Bullet](http://multithreaded.stitchfix.com/blog/2015/07/30/gam/) (Kim Larsen, Stichfix, 2015)

Prophet
========

* Facebook's [open-sourced](https://facebookincubator.github.io/prophet/) time-series Bayesian forecasting framework.
* Time is a covariate; Complex seasonality; Non-clockwork periods. 

$$ log(y) = s(time) + seasonality + holiday + changepoints + error$$

<center>
<img src="prophet.png" alt="Prophet" style="height: 300px;"/>
</center>

GAMLSS
======

* [Generalized Additive Models for Location, Scale, & Shape](http://gamlss.org)
* LSS = _Independently_ model all parameters of a distribution
* Arbitrary exponential-family distributions, e.g., Skew $t$, Zero-Inflated Poisson, Beta, dozens more...
* Forecast _shape of uncertainty_ in new cases

Here:

* Sales ~ spline(time, back to school)
* Var(Sales) ~ time 
* Tail-heaviness(Sales) ~ time


Modeling the Prior
==================

```{r prior, echo=TRUE}
monthly_training <- filter(monthly, set=="Train")
prior_fit <- gamlss(log(sales) ~ cs(t_mo) + bts,
                    sigma.formula = ~ t_mo,
                    nu.formula = ~ t_mo,
                    family=TF,
                    data=monthly_training,
            control=gamlss.control(trace=FALSE))
```

***

```{r prior_fit_out, echo=FALSE}
prior_fit
```


Modeling the Prior
==================

<center>
```{r prior_plots, echo=FALSE, fig.height=1.9, fig.width=3, dpi=150}
par(mai=c(.5,.54,.2,.25))
term.plot(prior_fit, terms = 1); title("Loc, cs(t_mo)")
term.plot(prior_fit, terms = 2); title("Loc, bts")
term.plot(prior_fit, what='sigma'); title("Scale, t_mo")
term.plot(prior_fit, what='nu'); title("Shape, t_mo")

```
</center>

Prior Plot
=========

```{r prior_fit, message=FALSE, warning=FALSE, results='hide'}
prior_dist <- function(t_mo, bts, 
                       sales_range=2000:15000) {
  with(predictAll(prior_fit, 
                  newdata=data.frame(t_mo=t_mo,
                                     bts=bts)),
       tibble(sales=sales_range,
              d=dTF(log(sales_range), mu=mu, 
                    sigma=sigma, nu=nu),
              t_mo=t_mo, bts=bts) %>%
         mutate(d=d/sum(d)))
}
samp_priors <- tibble(t_mo=c(15,36), 
                      bts=c(FALSE, TRUE)) %>%
  by_row(~ prior_dist(.$t_mo, .$bts), 
         .collate='rows') 
```

*** 

```{r oneprior, echo=FALSE, fig.height=3, fig.width=4}
samp_priors %>%
  ggplot(aes(sales, d, group=t_mo, color=t_mo)) + 
  geom_line(size=1.2) +
  xlab("Sales") + ylab("") + 
  theme(legend.position = 'none') 
```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
<h1>3. Updating the Prior</h1> 
</div>
</center>

Likelihood and Posterior, ECDFs
========================

* Prior = estimated monthly sales
* Likelihood = P(observing sales to date | prior, proportion of month)
* Posterior $\prop$ Prior * Likelihood

$$
P(\text{forecast sales}=y|\text{sales to date}=x) \propto P(\text{sales to date}=x | \text{fraction of month, forecast sales}=y) 
\cdot P(\text{forecast sales}=y) \\
\propto P(\text{fraction sales to date}=\frac{x}{y}|\text{fraction of month}) \cdot P(\text{forecast sales} = y)
$$

*** 

1. Simulate _distribution_ of proportion of sales under the timecourse model.
2. For any plausible number of final sales...
3. Multiply to get simulated distribution of sales (Likelihood).
4. Convert to ECDF.
5. Generate ECDF of Prior.
6. Multiply and normalize to get Posterior.


Modeling the Timecourse
=======================

* _Proportion of monthly sales_ as a function of proportion of
month in days
* As of the beginning of each day, so predictors can be zero but not one
* Zero-inflated Beta is in $[0, 1)$, 3 parameters.

```{r timecourse}
daily <- dat %>%
  group_by(t_mo) %>%
  mutate(monthly_sales=sum(sales),
         bod_sales=lag(sales, default = 0),
         prop_sales = cumsum(bod_sales) / monthly_sales,
         prop_month=(t_dom-1) / dpm) %>% ungroup()
head(daily)

```

Days and Business Days
======================

```{r timecourse_plot}
ggplot(daily, aes(prop_month, prop_sales, color=t_mo)) + 
  geom_point() +
  stat_smooth(aes(color=NULL), color='red') +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()

ggplot(daily, aes(prop_month, prop_sales, group=t_mo, color=set)) + 
  geom_line() +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  scale_color_manual("", values=c("black", "red")) +
  coord_equal()
  
```


Modeling the Timecourse (cont)
==============================

```{r timecourse_mod}
daily_training <- filter(daily, set=="Train")
timecourse_fit <- gamlss(prop_sales ~ cs(prop_month),
                         sigma.formula = ~ cs(prop_month),
                         nu.formula = ~ cs(prop_month),
                         data=daily_training,
                         family=BEINF0)

# get this in somehow!
pdf.plot(timecourse_fit, c(1, 15, 28), min=0, max=.99, step=.01)
```

Modeling the Timecourse (cont)
==============================

Model gives distribution parameters -- can get quantiles from there, e.g.:

```{r timecourse_forecast} 
# predict 5th percentile of 1/4 & 3/4 of the way through
with(predictAll(timecourse_fit, newdata=data_frame(prop_month=c(.25, .75))),
     qBEINF0(.05,  mu=mu, sigma=sigma, nu=nu))
```

```{r timecourse_mod2, echo=FALSE}
daily_preds <- with(predictAll(timecourse_fit,
                               newdata=data_frame(prop_month=(0:99)/100)),
               map_df(c(.05, .5, .95),
                      ~ data_frame(quantile=sprintf("q%0d", 100*.x), 
                                   prop_month=(0:99)/100,
                                   prop_sales=qBEINF0(.x, mu=mu, 
                                                 sigma=sigma, nu=nu)))) %>%
  spread(quantile, prop_sales)
head(daily_preds)
```

***

```{r timecourse_mod_plot}
ggplot(daily_preds, aes(prop_month, ymin=q5, ymax=q95, y=q50)) + 
  geom_ribbon(alpha=.5) + 
  geom_line() +
  geom_point(data=daily_training, 
             mapping=aes(ymin=NULL, ymax=NULL, y=prop_sales),
             color='blue', size=.5) +
  scale_x_continuous("Proportion of Month", labels = scales::percent) +
  scale_y_continuous("Proportion of Sales", labels = scales::percent) +
  coord_equal()
```

Updating
========

December 10, 2016. 2820 sales. Panic??

```{r std}
fc_day <- filter(daily, t_mo == 36) %>%
  mutate(bod_sales_cumul = cumsum(bod_sales)) %>%
  filter(t_dom == 10)

dSales <- function(covars, sales) {
  suppressWarnings(
    with(predictAll(prior_fit, covars, data=monthly_training), 
         dTF(log(sales), mu=mu, sigma=sigma, nu=nu))
  )
}

```

============
type:section

<center> 
<div>
<h1>1. Periodic Accumulating Processes</h1> 
<h1>2. Modeling the Prior</h1> 
<h1>3. Updating the Prior</h1> 
<h1>4. Step Back</h1> 
</div>
</center>

Visualizing and Backtesting
==========================

Impact
======


Caveats and Alternatives
=======================

daily model

Takeaways
======
type:section

* Bayesian Update for Accumulation
* GAMLSS for Flexible Distribution Models
* Honest Uncertainty

Harlan D. Harris, PhD <br>
[Twitter](http://twitter.com/harlanh), 
[Medium](http://medium.com/@harlanh), 
[GitHub](http://github.com/HarlanH): @harlanh

[This Presentation on GitHub](https://github.com/HarlanH/gamlss_accum)

Auto-regressive Models
======================

$$ X_t = c + \sum_{i=1}^p \phi_i X_{t-1} + \epsilon_t $$

```{r ar}
monthly_ts <- ts(filter(monthly, 
                        set=="Train")$sales, 
                 start=c(2014,1), frequency=12)
monthly_fc <- forecast(auto.arima(monthly_ts, 
                                  max.q=0), 3)
```

***

```{r ar_plot, echo=FALSE}
p <- autoplot(monthly_fc) +
  geom_point(aes(time, sales), 
             data=tibble(time=2016+(9:11)/12, 
              sales=filter(monthly, set=="Test")$sales),
             color='red') +
  scale_y_continuous("Sales", limits=c(0,NA)) +
  theme_minimal()
p
```
